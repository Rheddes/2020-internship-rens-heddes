from sqlalchemy import create_engine
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib import rcParams
import numpy as np
from scipy import stats
import mysql
import statsmodels.formula.api as smf
import powerlaw


def scatter_dist_old():
    query = """
        SELECT u.*, r.full_name, v.package_coords, v.first_fix_release_date, v.cvss_score, cves.* FROM updates u
        INNER JOIN repos r ON u.repo_id = r.id
        INNER JOIN vulnerabilities v ON u.cve = v.cve
        LEFT JOIN cves ON fixes_cve_id = cves.id
    """
    df = pd.read_sql(query, con=db_connection, parse_dates=['commit_date', 'old_release_date', 'new_release_date'])
    df['log_update_delay'] = np.log10(df['update_delay'])
    means = df.groupby('repo_id')['log_update_delay'].mean()
    stds = df.groupby('repo_id')['log_update_delay'].std()
    df['update_delay_deviation'] = df.apply(lambda row: row['update_delay'] - means[row['repo_id']], axis=1)
    df['normalized_update_delay_deviation'] = df.apply(lambda row: (row['update_delay'] - means[row['repo_id']])/stds[row['repo_id']], axis=1)
    df = df[df['cvss_v3'].notnull()]
    # sns.regplot(data=df, x='update_delay', y='cvss_v3', logx=True)
    # sns.regplot(data=df, x='update_delay', y='v2Score')
    # plt.title('Impact of CVSS score associated with vulnerability patch\n and update delay')
    # # plt.xlabel('Update delay to fixed version (days)')
    # plt.xlabel('Update delay deviation from repo update delay mean (days)')
    # plt.ylabel('CVSS score of patched vulnerability')
    # plt.ylim(1, 10)
    # plt.show()

    filtered = df[df['update_delay'] > 30]
    for score_column in cvss_score_columns:
        # sns.regplot(data=df, x='update_delay', y=score_column)
        # sns.regplot(data=filtered, x='update_delay', y=score_column)
        # plt.show()
        # sns.regplot(data=df, x='normalized_update_delay_deviation', y=score_column)
        sns.regplot(data=filtered, x='normalized_update_delay_deviation', y=score_column)
        plt.ylabel('CVSS score')
        plt.xlabel('Normalized update delay deviation from mean')
        plt.title('Impact of CVSS score associated with vulnerability patch\n and update delay')
        plt.show()
    # df['binned_v3'] = pd.cut(df['v3BaseScore'], 3, labels=['LOW', 'MEDIUM', 'HIGH'])
    # df['binned_v2'] = pd.cut(df['v2Score'], 3, labels=['LOW', 'MEDIUM', 'HIGH'])
    #
    # for category_column in cvss_category_columns:
    #     sns.boxplot(data=df, x=category_column, y='normalized_update_delay_deviation')
    #     plt.show()
    # sns.boxplot(data=df, x='v2Severity', y='update_delay_deviation', order=['LOW', 'MEDIUM', 'HIGH'])
    # plt.show()
    # sns.boxplot(data=df, x='v3BaseSeverity', y='update_delay_deviation', order=['LOW', 'MEDIUM', 'HIGH', 'CRITICAL'])
    # plt.show()
    return df, filtered


def _get_data():
    query = """
                SELECT u.*, r.full_name, r.is_vulnerable as uses_vulnerable_code, v.package_coords, v.first_fix_release_date, v.cvss_score, cves.* FROM updates u
                INNER JOIN repos r ON u.repo_id = r.id
                INNER JOIN vulnerabilities v ON u.cve = v.cve
                LEFT JOIN cves ON fixes_cve_id = cves.id
                WHERE is_fork = 0;
            """
    # v.cve = 'CVE-2020-8840' AND
    df = pd.read_sql(query, con=db_connection, parse_dates=['commit_date', 'old_release_date', 'new_release_date'])
    # deduplicate 'cve' column names
    df.columns = pd.io.parsers.ParserBase({'names': df.columns})._maybe_dedup_names(df.columns)
    df['log_update_delay'] = np.log10(df['update_delay'])
    means = df.groupby('repo_id')['log_update_delay'].mean()
    stds = df.groupby('repo_id')['log_update_delay'].std()
    df = df[df['repo_id'].isin(stds[stds > 0].index)]
    df['log_update_delay_Z'] = df.apply(
        lambda row: (row['log_update_delay'] - means[row['repo_id']]) / stds[row['repo_id']], axis=1)
    df['short_name'] = df.apply(lambda row: row['full_name'].split('/')[1], axis=1)
    df['unique_name'] = df.apply(lambda row: '{} - {}'.format(row['full_name'], row['cve']), axis=1)
    return df, means


def scatter_dist():
    df, means = _get_data()

    sns.displot(data=df, x='log_update_delay_Z', bins=65)
    plt.xlabel('Standardised log update delay')
    plt.title('Standardised log update delays for\nall updates across all scanned repositories')
    plt.show()

    testing_for_normality = False
    if testing_for_normality:
        for repo_id, count in list(result_all['repo_id'].value_counts().items())[:100]:
            df_repo = result_all[result_all['repo_id'] == repo_id]

            stat, p = stats.normaltest(df_repo['log_update_delay_Z'])
            print('---------STATS for {}--------'.format(repo_id))
            print('Statistics=%.3f, p=%.10f' % (stat, p))
            # interpret
            alpha = 0.05
            if p > alpha:
                print('Sample looks Gaussian (fail to reject H0)')
                sns.displot(data=df_repo, x='log_update_delay_Z')
                plt.title('Update delay distributions for repo {} ({} updates)'.format(repo_id, count))
                plt.show()
            else:
                print('Sample does not look Gaussian (reject H0)')

    df_all = df
    df = df[df['is_fix_update'] == 1].sort_values(by=['log_update_delay_Z'])

    g = sns.barplot(data=df, x='unique_name', y='log_update_delay_Z', hue='uses_vulnerable_code', dodge=False, ci=False)
    g.set_xticklabels(g.get_xticklabels(), rotation=90)  # , horizontalalignment='right')
    plt.xlabel('Repository')
    plt.ylabel('Normalized update delay deviation from mean')
    plt.title('Distribution of normalised fix update delay deviations')
    g.set_xticklabels([])
    plt.show()

    for cve in df['cve'].unique():
        df_cve = df[df['cve'] == cve]
        if df_cve.shape[0] < 20:
            print('Skipping on {}'.format(cve))
            continue
        print(cve)
        g = sns.barplot(data=df_cve, x='short_name', y='log_update_delay_Z', hue='uses_vulnerable_code',
                        dodge=False, ci=False)
        g.set_xticklabels(g.get_xticklabels(), rotation=90)  # , horizontalalignment='right')
        plt.xlabel('Repository')
        plt.ylabel('Normalized update delay deviation from mean')
        plt.title('Distribution of normalised fix update delay deviations\n for {}'.format(cve))
        vulnerable_short_names = df_cve[df_cve['uses_vulnerable_code'] == 1]['short_name'].to_list()
        for n, label in enumerate(g.get_xticklabels()):
            if label.get_text() not in vulnerable_short_names:
                label.set_visible(False)
        plt.show()

    print(df['log_update_delay_Z'].describe())

    cve_update_delays = df.groupby('cve').agg({'log_update_delay_Z': 'mean', 'cvss_score': 'min'})
    sns.regplot(data=cve_update_delays, x='cvss_score', y='log_update_delay_Z')
    plt.show()
    return df, df_all


def plot_for_single_repo():
    repo_id = 745
    df, means = _get_data()
    repo_df = df[df['repo_id'] == repo_id]
    sns.displot(data=repo_df, x='update_delay')
    plt.xlabel('Update delay in days')
    plt.xlim(0, 800)
    plt.title('Absolute update delay (in number of days)\n for "Apache/Tika"')
    plt.show()

    sns.displot(data=repo_df, x='log_update_delay', kde=True)
    plt.xlabel('Log(Update delay in days)')
    plt.title('Log of update delay for "Apache/Tika"')
    plt.show()
    return repo_df



if __name__ == '__main__':
    rcParams.update({'figure.autolayout': True})
    db_connection_str = 'mysql+mysqlconnector://vulnerability-history:secret@localhost:33062/vulnerability-history'
    db_connection = create_engine(db_connection_str)
    cvss_category_columns = [
        'v2Severity',
        'v2UserInteractionRequired',
        'v2AccessVector',
        'v2AccessComplexity', #somewhat
        'v2ConfidentialityImpact',
        'v2IntegrityImpact',
        'v2AvailabilityImpact',
        'v3AttackVector',
        'v3AttackComplexity',
        'v3PrivilegesRequired',
        'v3UserInteraction',
        'v3ConfidentialityImpact',
        'v3IntegrityImpact',
        'v3AvailabilityImpact',
        'v3BaseSeverity',
    ]
    cvss_score_columns = [
        'v3BaseScore',
        'v3ImpactScore',
        'v3ExploitabilityScore',
        # 'v2ExploitabilityScore',
        # 'v2ImpactScore',
        # 'v2Score',
    ]


    # dat, filtered_dat = scatter_dist_old()
    # results = smf.ols('update_delay ~ v3BaseScore + v3ExploitabilityScore', data=filtered_dat).fit()
    # print(results.summary())
    # results = smf.ols('normalized_update_delay_deviation ~ v3BaseScore + v3ExploitabilityScore', data=filtered_dat).fit()
    # print(results.summary())

    result_repo = plot_for_single_repo()

    # result, result_all = scatter_dist()
    # print(result.query('uses_vulnerable_code == True and log_update_delay_Z > 0'))

    # selection = result.query('uses_vulnerable_code == True and log_update_delay_Z > 0')
    # selection = selection[['package', 'commit_hash', 'commit_date', 'commit_author', 'new_version', 'full_name']]
    # selection['commit_link'] = selection.apply(lambda row: 'https://github.com/{}/commit/{}'.format(row['full_name'], row['commit_hash']), axis=1)

    # results = powerlaw.Fit(result['update_delay'])
    # print(results)

    # query = """
    #     SELECT u.*, r.full_name, v.package_coords, v.first_fix_release_date FROM updates u
    #     INNER JOIN repos r ON u.repo_id = r.id
    #     INNER JOIN vulnerabilities v on u.cve = v.cve
    #     WHERE is_fork = 0
    # """
    # df = pd.read_sql(query, con=db_connection, parse_dates=['commit_date', 'old_release_date', 'new_release_date'])
    #
    # dom4j_all_updates = df[df['cve'] == 'CVE-2020-10683']
    # dom4j_patch_updates = dom4j_all_updates[dom4j_all_updates['is_fix_update'] == 1]
    #
    # compress_all_updates = df[df['cve'] == 'CVE-2019-12402']
    # compress_patch_updates = compress_all_updates[compress_all_updates['is_fix_update'] == 1]
    # # sns.ecdfplot(dom4j_all_updates['update_delay'])
    # # plt.show()
    # # print(dom4j_all_updates.quantile(0.6))
    # # print(dom4j_all_updates.quantile(0.8))
    #
    # sns.ecdfplot(dom4j_all_updates['update_delay'], color=sns.color_palette()[0])
    # sns.ecdfplot(dom4j_patch_updates['update_delay'], color=sns.color_palette()[1])
    # plt.legend(labels=['overall update delay', 'dom4j patch fix delay'])
    # plt.xlim(0, 1500)
    # plt.title('Update distribution for repositories which use dom4j')
    # plt.tight_layout()
    # plt.show()
    # sns.ecdfplot(compress_all_updates['update_delay'], color=sns.color_palette()[0])
    # sns.ecdfplot(compress_patch_updates['update_delay'], color=sns.color_palette()[1])
    # plt.legend(labels=['overall update delay', 'apache compress patch fix delay'])
    # plt.xlim(0, 1500)
    # plt.title('Update distribution for repositories which\n use Apache Commons-compress')
    # plt.tight_layout()
    # plt.show()
    # # print(dom4j_patch_updates.quantile(0.6))
    # # print(dom4j_patch_updates.quantile(0.8))
    # # sns.displot(dom4j_all_updates['update_delay'], kde=True, binwidth=5)
    # # plt.show()
    # # sns.displot(dom4j_all_updates['update_delay'], kind='kde', bw_adjust=0.25)
    # # plt.show()
    # # sns.displot(dom4j_patch_updates['update_delay'], kde=True, binwidth=5)
    # # plt.show()
    # # sns.displot(dom4j_patch_updates['update_delay'], kind='kde', bw_adjust=0.25)
    # # plt.show()
    # # sns.displot(compress_patch_updates['update_delay'], kind='kde', bw_adjust=0.25)
    # # plt.show()
    # # commit_counts = dom4j_all_updates.groupby(['commit_hash']).agg(len)
    # # sns.displot(commit_counts['id'], binwidth=3)
    # # plt.xlabel('Number of updates in commit')
    # # plt.xlim(0, 200)
    # # plt.show()
    # # sns.displot(commit_counts['id'], binwidth=1)
    # # plt.xlabel('Number of updates in commit')
    # # plt.xlim(0, 50)
    # # plt.show()
    # # print(commit_counts)
    #
    # commits = df.groupby('commit_date').count().sort_values(by='commit_date', ascending=True)
    # commits_keycloak = dom4j_all_updates[dom4j_all_updates['repo_id'] == 83].groupby('commit_date').count().sort_values(by='commit_date', ascending=True)
    # commits['monthly_commit_average'] = commits.commit_hash.rolling(28).mean().shift(-3)
    # commits_keycloak['weekly_commit_average'] = commits_keycloak.commit_hash.rolling(7).mean().shift(-3)
    #
    # sns.displot(data=dom4j_all_updates, x='commit_date', kind='kde')
    # plt.title('Updates performed')
    # # sns.lineplot(data=commits,
    # #              x='commit_date',
    # #              y='monthly_commit_average').set_title('Commits')
    # plt.tight_layout()
    # plt.show()
    # # interesting_repo_ids = [62, 98, 108, 112]
    # interesting_repo_ids = [62, 45, 78, 69]
    # for repo_id in interesting_repo_ids:
    #     repo_commits = df[df['repo_id'] == repo_id]
    #     repo_name = repo_commits['full_name'].iloc[0]
    #     print(repo_name)
    #     sns.displot(data=repo_commits, x='commit_date', kind='kde')
    #     plt.title('Updates ({}) in {}'.format(len(repo_commits), repo_name))
    #     plt.tight_layout()
    #     plt.show()
